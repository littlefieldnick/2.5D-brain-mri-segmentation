{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/littlefieldnick/2.5D-brain-mri-segmentation/blob/master/Code/FewShotSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTYVyaNi8-V_"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models-pytorch grad-cam --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import gdown\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch import utils as smp_utils\n",
        "\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
        "\n",
        "\n",
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "rOe1s38U9DjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Setup"
      ],
      "metadata": {
        "id": "ol7-q1rCsoUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/pitthexai/IEEE_BHI_2023_Tutorial_From_Few_to_None/raw/bcce5fd52b349659fb03fd065f9037e70acc83a9/SampleDataset/BHI_Segmentation.zip\n",
        "! unzip /content/BHI_Segmentation.zip"
      ],
      "metadata": {
        "id": "7Drx1f2R95V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"/content/BHI_Segmentation\"\n",
        "SAVE_DIR = \"/content/checkpoints/\"\n",
        "SHOT = 10\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "RANDOM_STATE = 42"
      ],
      "metadata": {
        "id": "hX9-JbPk99-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JointSpaceSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_root, mask_root, image_files, mask_files, transforms=None, preprocessing=None):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.img_files = image_files\n",
        "        self.mask_files = mask_files\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(os.path.join(self.img_root, self.img_files[idx])))\n",
        "        mask = np.array(Image.open(os.path.join(self.mask_root, self.mask_files[idx])))\n",
        "\n",
        "        # image = np.stack([image, image, image], axis=0)\n",
        "        # mask = np.expand_dims(mask, axis=0)\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "        mask = torch.unsqueeze(mask, 0)\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "\n",
        "        return image.type(torch.FloatTensor), mask/255.0"
      ],
      "metadata": {
        "id": "kEEdc-Bb-IR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def generate_datasets(root_dir):\n",
        "    x_dir = os.path.join(root_dir, \"Images\")\n",
        "    y_dir = os.path.join(root_dir, \"Annotations\")\n",
        "    records = [[img.split(\".\")[0][:-1], img, img] for img in os.listdir(x_dir) if img != \".DS_Store\"]\n",
        "\n",
        "    data_records = pd.DataFrame(records, columns=[\"pid\", \"images\", \"masks\"])\n",
        "\n",
        "    train, test = train_test_split(data_records.pid.unique(), test_size=0.5, random_state=RANDOM_STATE)\n",
        "    valid, test = train_test_split(test, test_size=0.5, random_state=RANDOM_STATE)\n",
        "\n",
        "    train = data_records[data_records.pid.isin(train)].reset_index(drop=True)\n",
        "    valid = data_records[data_records.pid.isin(valid)].reset_index(drop=True)\n",
        "    test = data_records[data_records.pid.isin(test)].reset_index(drop=True)\n",
        "\n",
        "    return train, valid, test"
      ],
      "metadata": {
        "id": "WoPnHYmVAUOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_few_shot_sample(dataset, k=1, random_state=RANDOM_STATE):\n",
        "    if k > len(dataset):\n",
        "        return dataset\n",
        "\n",
        "    return dataset.sample(k, random_state=random_state).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "5ycmpD7rAd5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid, test = generate_datasets(os.path.join(DATA_ROOT))"
      ],
      "metadata": {
        "id": "ozHTHTWrAtbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_few = get_few_shot_sample(train, k=SHOT)\n",
        "valid_few = get_few_shot_sample(valid, k=SHOT)"
      ],
      "metadata": {
        "id": "xZNFQ-_gAzNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_few, valid_few"
      ],
      "metadata": {
        "id": "VSkyWAbOBovZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessing_fn(encoder, encoder_weights):\n",
        "    return smp.encoders.get_preprocessing_fn(encoder, encoder_weights)\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "\n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function\n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _transform = [\n",
        "        A.Lambda(image=preprocessing_fn),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        "    return A.Compose(_transform)"
      ],
      "metadata": {
        "id": "BiVsrVj0A3Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(SAVE_DIR):\n",
        "    os.makedirs(SAVE_DIR)"
      ],
      "metadata": {
        "id": "hML-0bLaKxZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_augmentations = A.Compose([A.Resize(256, 256), A.Rotate(15), A.RandomBrightness(0.2),\n",
        "                                 A.RandomContrast(0.2),  ToTensorV2()])\n",
        "\n",
        "test_augmentations = A.Compose([A.Resize(256, 256), ToTensorV2()])\n",
        "train_set = JointSpaceSegmentationDataset(os.path.join(DATA_ROOT, \"Images\"),\n",
        "                                          os.path.join(DATA_ROOT, \"Annotations\"),\n",
        "                                          train_few.images, train_few.masks,\n",
        "                                          preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
        "                                          transforms=train_augmentations)\n",
        "\n",
        "valid_set = JointSpaceSegmentationDataset(os.path.join(DATA_ROOT, \"Images\"),\n",
        "                                          os.path.join(DATA_ROOT, \"Annotations\"),\n",
        "                                          valid_few.images, valid_few.masks,\n",
        "                                          preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
        "                                          transforms=test_augmentations)\n",
        "\n",
        "test_set = JointSpaceSegmentationDataset(os.path.join(DATA_ROOT, \"Images\"),\n",
        "                                         os.path.join(DATA_ROOT, \"Annotations\"),\n",
        "                                         test.images, test.masks,\n",
        "                                         preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
        "                                         transforms=test_augmentations)"
      ],
      "metadata": {
        "id": "0ajiW_Z_A7j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "HW_d6dbessSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = \"resnet18\"\n",
        "encoder_weights = \"imagenet\"\n",
        "activation = \"sigmoid\"\n",
        "num_classes = 1 # 0=background, 1=joint space"
      ],
      "metadata": {
        "id": "y7TDc-gQA53Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "model = copy.deepcopy(smp.Unet(encoder_name=encoder, encoder_weights=encoder_weights, in_channels=1,\n",
        "                 classes=num_classes, activation=activation))\n",
        "model.encoder.requires_grad_ = True\n",
        "model = model.to(DEVICE)\n",
        "loss = nn.BCELoss()\n",
        "loss.__name__=\"loss\"\n",
        "metrics = [smp_utils.metrics.IoU(threshold=0.5, activation=None), smp_utils.metrics.Fscore(0.5, activation=None)]\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-04)"
      ],
      "metadata": {
        "id": "h4Y5Bu1dBK89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=2, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=2, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "RUfI5BGfBNBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create epoch runners\n",
        "# it is a simple loop of iterating over dataloader`s samples\n",
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model,\n",
        "    loss=loss,\n",
        "    metrics=metrics,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "FiR3PLn5BrvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model for 40 epochs\n",
        "\n",
        "max_score = 0\n",
        "\n",
        "for i in range(1, 101):\n",
        "\n",
        "    print('\\nEpoch: {}'.format(i))\n",
        "    train_logs = train_epoch.run(train_loader)\n",
        "    valid_logs = valid_epoch.run(valid_loader)\n",
        "\n",
        "    # do something (save model, change lr, etc.)\n",
        "    if max_score < valid_logs['iou_score']:\n",
        "        max_score = valid_logs['iou_score']\n",
        "        torch.save(model, f'{SAVE_DIR}/best_model_{SHOT}_shot.pth')\n",
        "        print('Model saved!')\n"
      ],
      "metadata": {
        "id": "UJmmgjkvBtMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing"
      ],
      "metadata": {
        "id": "q2zDi6HgswtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2)\n",
        "test_img, test_mask  = next(iter(test_loader))"
      ],
      "metadata": {
        "id": "KfnwCPLjByYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(f'{SAVE_DIR}/best_model_{SHOT}_shot.pth')\n",
        "model = model.cuda()\n",
        "\n",
        "avg_iou = 0.0\n",
        "avg_fscore = 0.0\n",
        "iou_metric = smp.utils.metrics.IoU(threshold=0.5)\n",
        "fscore_metric = smp.utils.metrics.Fscore(threshold=0.5)\n",
        "for img, mask in test_loader:\n",
        "    out = model(img.to(DEVICE))\n",
        "    mask = mask.to(DEVICE)\n",
        "    avg_iou += iou_metric(out, mask).item()\n",
        "    avg_fscore += fscore_metric(out, mask).item()\n",
        "\n",
        "print(f\"Test IoU: {avg_iou/len(test_loader)}\\nTest Dice Score: {avg_fscore/len(test_loader)}\")"
      ],
      "metadata": {
        "id": "BUF9MpsTDOIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(5, 3, figsize=(10, 10), sharex=True, sharey=True)\n",
        "fig.suptitle(f\"Few-Shot Segmentation Results (K = {SHOT})\")\n",
        "for i, (img, mask) in enumerate(test_loader):\n",
        "    ax[i, 0].imshow(img[0][0,:,:].squeeze(),cmap=\"gray\")\n",
        "    ax[i, 0].set_title(\"X-Ray\")\n",
        "    ax[i, 1].imshow(mask.squeeze())\n",
        "    ax[i, 1].set_title(\"Mask\")\n",
        "    ax[i, 2].imshow(torch.sigmoid(model(img.to(DEVICE)).squeeze().detach().cpu()).numpy())\n",
        "    ax[i, 2].set_title(\"Predicted Mask\")\n",
        "\n",
        "    if (i + 1) == 5:\n",
        "        break"
      ],
      "metadata": {
        "id": "Zww2RkqHDQKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing Different $K$-shot values"
      ],
      "metadata": {
        "id": "Mo8VWZrXs1Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download(id=\"1Tb3uhEfukPaFgc6KiKOpTUrpQAS1YkN8\", output=\"/content/\")"
      ],
      "metadata": {
        "id": "LynX3K0Pd-Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/checkpoints.zip"
      ],
      "metadata": {
        "id": "uFmjqFkoenUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_iou = []\n",
        "few_dice = []\n",
        "\n",
        "for shot in [1, 3, 5, 7, 10]:\n",
        "    _, _, test = generate_datasets(os.path.join(DATA_ROOT))\n",
        "    test_data = get_few_shot_sample(test, k=shot)\n",
        "    test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "    model = torch.load(f'{SAVE_DIR}/best_model_{shot}_shot.pth')\n",
        "    model = model.cuda()\n",
        "\n",
        "\n",
        "    avg_iou = 0.0\n",
        "    avg_fscore = 0.0\n",
        "    iou_metric = smp.utils.metrics.IoU(threshold=0.5)\n",
        "    fscore_metric = smp.utils.metrics.Fscore(threshold=0.5)\n",
        "    for img, mask in test_loader:\n",
        "        out = model(img.to(DEVICE))\n",
        "        mask = mask.to(DEVICE)\n",
        "        avg_iou += iou_metric(out, mask).item()\n",
        "        avg_fscore += fscore_metric(out, mask).item()\n",
        "    few_iou.append(avg_iou/len(test_loader))\n",
        "    few_dice.append(avg_fscore/len(test_loader))"
      ],
      "metadata": {
        "id": "guadYtPyOFyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([1, 3, 5, 7, 10], few_iou)\n",
        "plt.plot([1, 3, 5, 7, 10], few_dice)\n",
        "plt.xlabel(\"K-Shot\")\n",
        "plt.ylabel(\"IoU/Dice Score\")\n",
        "plt.title(\"K-Shot IoU vs. Dice Score\")\n",
        "plt.legend([\"IoU\", \"Dice Score\"])"
      ],
      "metadata": {
        "id": "QZw9Y4EjetEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explainability"
      ],
      "metadata": {
        "id": "r_lGDIrltAH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GradCamSampler(nn.Module):\n",
        "    def __init__(self, img_root, mask_root, image_files, mask_files, transforms=None, preprocessing=None, samples_to_generate=5):\n",
        "        self.img_root = img_root\n",
        "        self.mask_root = mask_root\n",
        "        self.img_files = image_files\n",
        "        self.mask_files = mask_files\n",
        "        self.samples_to_generate = samples_to_generate\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def _sample_images_for_gradcam(self):\n",
        "        sample_ids = np.random.choice(range(len(self.img_files)), size=self.samples_to_generate)\n",
        "        self.ids = sample_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.samples_to_generate\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(os.path.join(self.img_root, self.img_files[idx])))\n",
        "        mask = np.array(Image.open(os.path.join(self.mask_root, self.mask_files[idx])))\n",
        "\n",
        "        # image = np.stack([image, image, image], axis=-1)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "        # mask = torch.unsqueeze(mask, 0)\n",
        "\n",
        "        if self.preprocessing is not None:\n",
        "            transformed = self.preprocessing(image=image)\n",
        "            image = transformed[\"image\"]\n",
        "            # mask = transformed[\"mask\"]\n",
        "\n",
        "        return image.type(torch.FloatTensor), mask/255.0"
      ],
      "metadata": {
        "id": "Y5koZzD2evoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentations = A.Compose([A.Resize(256, 256), ToTensorV2()])\n",
        "\n",
        "test_set = GradCamSampler(os.path.join(DATA_ROOT, \"Images\"),\n",
        "                                         os.path.join(DATA_ROOT, \"Annotations\"),\n",
        "                                         test.images, test.masks,\n",
        "                                         preprocessing=None,#get_preprocessing(preprocessing_fn),\n",
        "                                         transforms=test_augmentations)"
      ],
      "metadata": {
        "id": "ROmx-7bJgUx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2)\n",
        "test_img, test_mask  = next(iter(test_loader))"
      ],
      "metadata": {
        "id": "WOda4cnwgbD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SemanticSegmentationTarget:\n",
        "    def __init__(self, category, mask):\n",
        "        self.category = category\n",
        "        if type(mask) == np.array:\n",
        "            self.mask = torch.from_numpy(mask)\n",
        "        else:\n",
        "            self.mask = mask\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.mask = self.mask.cuda()\n",
        "\n",
        "    def __call__(self, model_output):\n",
        "        print(self.mask.shape == model_output.shape)\n",
        "        return (model_output[self.category,:,:] * self.mask).sum()\n"
      ],
      "metadata": {
        "id": "5OaBL15sgdkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_layers = [model.decoder, model.segmentation_head]\n",
        "iou = smp_utils.metrics.IoU(threshold=0.5)\n",
        "\n",
        "with GradCAM(model=model,\n",
        "             target_layers=target_layers,\n",
        "             use_cuda=torch.cuda.is_available()) as cam:\n",
        "\n",
        "    fig, ax = plt.subplots(len(test_loader), 4, figsize=(10, 10), sharex=True, sharey=True)\n",
        "\n",
        "    for i, (test_img, test_mask) in enumerate(test_loader):\n",
        "        targets = [SemanticSegmentationTarget(0, test_mask)]\n",
        "\n",
        "        grayscale_cam = cam(input_tensor=test_img,\n",
        "                            targets=targets)[0, :]\n",
        "\n",
        "        test_img2= test_img.squeeze().squeeze().detach().cpu().numpy()/255.0\n",
        "        test_img2 = np.stack([test_img2, test_img2, test_img2], axis=-1)\n",
        "\n",
        "        cam_image = show_cam_on_image(test_img2, grayscale_cam, use_rgb=True)\n",
        "        out = model(test_img.to(DEVICE))\n",
        "\n",
        "        ax[i, 0].imshow(test_img[0][0,:,:].squeeze(),cmap=\"gray\")\n",
        "        ax[i, 0].set_title(\"X-Ray\")\n",
        "        ax[i, 1].imshow(test_mask.squeeze())\n",
        "        ax[i, 1].set_title(\"Mask\")\n",
        "        ax[i, 2].imshow(torch.sigmoid(out).squeeze().detach().cpu().numpy())\n",
        "        ax[i, 2].set_title(\"Predicted Mask\")\n",
        "        ax[i, 3].imshow(Image.fromarray(cam_image))\n",
        "        ax[i, 3].set_title(\"Grad-CAM\")"
      ],
      "metadata": {
        "id": "cEwHjY-dgdhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VH6y5GAlgdcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "shmVj3vogdLz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}